---
layout: post
title: "Neural Network use in simple image classification"
subtitle: "MNIST - the \"Hello, World!\" of Machine Learning"
date: 2020-09-25 20:17:03 -0500
background: '/img/posts/00.jpg'
---

<p>This project revolves around a simple neural network I decided to create in order 
    to get some hands-on experience with the mathematics behind backpropagation. 
    The network trains and makes predictions on probably the most recognizable Machine 
    Learning dataset there is - the MNIST handwritten digits dataset.</p>

<h2 class="section-heading">Network Architecture</h2>

<p>
    Since this is my first ML project, the architecture of this network isn't very complex - 
    it consists of a 784-node input layer, one 128-node hidden layer, and a 10-node output 
    layer. The network is capable of training on batches of sample data. My current implementation 
    doesn't allow for customizing the number or size of hidden layers, although I might 
    return to this project and update it in the future.
</p>

<p> 
    As the activation function, I chose to use sigmoid for the hidden layer and softmax 
    for the output layer (since the network deals with a classification problem). The cost 
    function is Mean Squared Error.
</p>

<h2 class="section-heading">The MNIST Dataset</h2>

<p>A description of the MNIST Handwritten Digits dataset will appear here.</p>

<h2 class="section-heading">The Results</h2>

<p>A short summary of what to expect in this section will appear here.</p>

<img class="img-fluid" src="/img/posts/00_results.png" alt="Results">
<span class="caption text-muted">The image label will appear here.</span>

<p>An analysis of the network's results will appear here.</p>

<h2 class="section-heading">Try It Yourself</h2>

<p>
    Batch size, as well as the size of the training dataset, the learning rate, and the 
    number of epochs to train for, are all customizable parameters. Detailed instructions 
    on how to modify the network to your liking can be found in the source code.
</p>

<p>
    Explore the network yourself through <a href="http://github.com/worthy11/MNIST-Neural-Network">my repository</a>.
    Feel free to provide feedback on how to make this project better!
</p>